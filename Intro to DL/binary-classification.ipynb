{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1480608,"sourceType":"datasetVersion","datasetId":829369}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Setup plotting\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn-whitegrid')\n# Set Matplotlib defaults\nplt.rc('figure', autolayout=True)\nplt.rc('axes', labelweight='bold', labelsize='large',\n       titleweight='bold', titlesize=18, titlepad=10)\nplt.rc('animation', html='html5')\n\n# Setup feedback system\nfrom learntools.core import binder\nbinder.bind(globals())\nfrom learntools.deep_learning_intro.ex6 import *","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-16T03:27:32.595668Z","iopub.execute_input":"2025-10-16T03:27:32.595897Z","iopub.status.idle":"2025-10-16T03:27:35.031688Z","shell.execute_reply.started":"2025-10-16T03:27:32.595872Z","shell.execute_reply":"2025-10-16T03:27:35.030658Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_37/3338970720.py:3: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n  plt.style.use('seaborn-whitegrid')\n/usr/local/lib/python3.11/dist-packages/learntools/deep_learning_intro/ex6.py:52: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n  if layer.__class__.__name__ is 'Dense']\n/usr/local/lib/python3.11/dist-packages/learntools/deep_learning_intro/ex6.py:59: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n  if layer.__class__.__name__ is 'Dense']\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.compose import make_column_transformer\n\nhotel = pd.read_csv('../input/dl-course-data/hotel.csv')\n\nX = hotel.copy()\ny = X.pop('is_canceled')\n\nX['arrival_date_month'] = \\\n    X['arrival_date_month'].map(\n        {'January':1, 'February': 2, 'March':3,\n         'April':4, 'May':5, 'June':6, 'July':7,\n         'August':8, 'September':9, 'October':10,\n         'November':11, 'December':12}\n    )\n\nfeatures_num = [\n    \"lead_time\", \"arrival_date_week_number\",\n    \"arrival_date_day_of_month\", \"stays_in_weekend_nights\",\n    \"stays_in_week_nights\", \"adults\", \"children\", \"babies\",\n    \"is_repeated_guest\", \"previous_cancellations\",\n    \"previous_bookings_not_canceled\", \"required_car_parking_spaces\",\n    \"total_of_special_requests\", \"adr\",\n]\nfeatures_cat = [\n    \"hotel\", \"arrival_date_month\", \"meal\",\n    \"market_segment\", \"distribution_channel\",\n    \"reserved_room_type\", \"deposit_type\", \"customer_type\",\n]\n\ntransformer_num = make_pipeline(\n    SimpleImputer(strategy=\"constant\"), # there are a few missing values\n    StandardScaler(),\n)\ntransformer_cat = make_pipeline(\n    SimpleImputer(strategy=\"constant\", fill_value=\"NA\"),\n    OneHotEncoder(handle_unknown='ignore'),\n)\n\npreprocessor = make_column_transformer(\n    (transformer_num, features_num),\n    (transformer_cat, features_cat),\n)\n\n# stratify - make sure classes are evenlly represented across splits\nX_train, X_valid, y_train, y_valid = \\\n    train_test_split(X, y, stratify=y, train_size=0.75)\n\nX_train = preprocessor.fit_transform(X_train)\nX_valid = preprocessor.transform(X_valid)\n\ninput_shape = [X_train.shape[1]]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T03:27:54.692009Z","iopub.execute_input":"2025-10-16T03:27:54.693745Z","iopub.status.idle":"2025-10-16T03:27:56.297673Z","shell.execute_reply.started":"2025-10-16T03:27:54.693682Z","shell.execute_reply":"2025-10-16T03:27:56.296337Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# Define Model","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nclass BinaryClassifier(nn.Module):\n    def __init__(self, input_size):\n        super(BinaryClassifier, self).__init__()\n        \n        self.input_bn = nn.BatchNorm1d(input_size)\n        \n        self.layer1 = nn.Linear(input_size, 256)\n        self.relu1 = nn.ReLU()\n        self.bn1 = nn.BatchNorm1d(256)\n        \n        self.dropout1 = nn.Dropout(0.3)\n        self.layer2 = nn.Linear(256, 256)\n        self.relu2 = nn.ReLU()\n        self.bn2 = nn.BatchNorm1d(256)\n        \n        self.dropout2 = nn.Dropout(0.3)\n        self.output_layer = nn.Linear(256, 1)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        x = self.input_bn(x)\n        x = self.relu1(self.layer1(x))\n        x = self.bn1(x)\n        \n        x = self.dropout1(x)\n        x = self.relu2(self.layer2(x))\n        x = self.bn2(x)\n        \n        x = self.dropout2(x)\n        x = self.sigmoid(self.output_layer(x))\n        return x\n\n# Assuming input_size is defined as 33\n# The input_shape is already defined correctly in the provided code\n# input_shape = [X_train.shape[1]]\n# So, you just need to use it.\n\n# Now, use the correct shape to initialize the model\ninput_size = X_train.shape[1]\nmodel = BinaryClassifier(input_size)\n\n# The rest of your code for compilation, training, and evaluation\n# will work correctly after this fix.\nmodel = BinaryClassifier(input_size)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T03:31:02.672768Z","iopub.execute_input":"2025-10-16T03:31:02.673073Z","iopub.status.idle":"2025-10-16T03:31:02.689363Z","shell.execute_reply.started":"2025-10-16T03:31:02.673050Z","shell.execute_reply":"2025-10-16T03:31:02.688345Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"import torch.optim as optim\n\n# Define the loss function and optimizer\ncriterion = nn.BCELoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T03:31:05.255723Z","iopub.execute_input":"2025-10-16T03:31:05.256082Z","iopub.status.idle":"2025-10-16T03:31:05.261777Z","shell.execute_reply.started":"2025-10-16T03:31:05.256049Z","shell.execute_reply":"2025-10-16T03:31:05.260677Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Convert data to PyTorch tensors\nX_train_tensor = torch.tensor(X_train, dtype=torch.float32)\ny_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).unsqueeze(1)\nX_valid_tensor = torch.tensor(X_valid, dtype=torch.float32)\ny_valid_tensor = torch.tensor(y_valid.values, dtype=torch.float32).unsqueeze(1)\n\n# Training loop\nepochs = 100\nfor epoch in range(epochs):\n    # Set the model to training mode\n    model.train()\n    \n    # Forward pass\n    outputs = model(X_train_tensor)\n    loss = criterion(outputs, y_train_tensor)\n    \n    # Backward pass and optimize\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n    \n    if (epoch+1) % 10 == 0:\n        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T03:31:06.145941Z","iopub.execute_input":"2025-10-16T03:31:06.146275Z","iopub.status.idle":"2025-10-16T03:33:28.818677Z","shell.execute_reply.started":"2025-10-16T03:31:06.146250Z","shell.execute_reply":"2025-10-16T03:33:28.817650Z"}},"outputs":[{"name":"stdout","text":"Epoch [10/100], Loss: 0.4756\nEpoch [20/100], Loss: 0.4455\nEpoch [30/100], Loss: 0.4281\nEpoch [40/100], Loss: 0.4195\nEpoch [50/100], Loss: 0.4120\nEpoch [60/100], Loss: 0.4064\nEpoch [70/100], Loss: 0.4011\nEpoch [80/100], Loss: 0.3975\nEpoch [90/100], Loss: 0.3938\nEpoch [100/100], Loss: 0.3899\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Evaluate the model\nmodel.eval()\nwith torch.no_grad():\n    y_pred_tensor = model(X_valid_tensor)\n    y_pred_class = (y_pred_tensor > 0.5).float()\n    \n    correct = (y_pred_class == y_valid_tensor).sum().item()\n    total = y_valid_tensor.shape[0]\n    accuracy = correct / total\n    \n    print(f'Accuracy on the validation set: {accuracy * 100:.2f}%')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T03:34:00.834620Z","iopub.execute_input":"2025-10-16T03:34:00.835026Z","iopub.status.idle":"2025-10-16T03:34:00.987365Z","shell.execute_reply.started":"2025-10-16T03:34:00.834998Z","shell.execute_reply":"2025-10-16T03:34:00.986294Z"}},"outputs":[{"name":"stdout","text":"Accuracy on the validation set: 82.12%\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}