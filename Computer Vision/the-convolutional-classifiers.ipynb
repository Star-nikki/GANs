{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1495782,"sourceType":"datasetVersion","datasetId":878523}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Imports\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nfrom torchvision import datasets, transforms\nimport matplotlib.pyplot as plt\nimport os\nfrom torch.utils.data import DataLoader\n\n# Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# Data transformations\n# The original Keras code used image_size=[128, 128], but InceptionV1\n# typically expects input sizes of at least 224x224.\n# We'll stick to 128x128 to match the original example, but a larger\n# size might yield better results.\n# The original example also used 'binary' labels, so we'll adjust the loss\n# function later to handle this.\ntransform = transforms.Compose([\n    transforms.Resize((128, 128)),\n    transforms.ToTensor(),\n    # The original Keras code didn't specify normalization values, but InceptionV1\n    # pretrained on ImageNet uses specific mean and std values.\n    # We will use these for best performance.\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\n# Load training and validation sets\ndata_dir = '../input/car-or-truck'\ntrain_dir = os.path.join(data_dir, 'train')\nvalid_dir = os.path.join(data_dir, 'valid')\n\nds_train_ = datasets.ImageFolder(train_dir, transform=transform)\nds_valid_ = datasets.ImageFolder(valid_dir, transform=transform)\n\n# Create data loaders\nbatch_size = 64\nds_train = DataLoader(ds_train_, batch_size=batch_size, shuffle=True)\nds_valid = DataLoader(ds_valid_, batch_size=batch_size, shuffle=False)\n\nprint(f\"Found {len(ds_train_)} files belonging to {len(ds_train_.classes)} classes.\")\nprint(f\"Found {len(ds_valid_)} files belonging to {len(ds_valid_.classes)} classes.\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-16T03:53:09.887463Z","iopub.execute_input":"2025-10-16T03:53:09.887705Z","iopub.status.idle":"2025-10-16T03:53:28.720013Z","shell.execute_reply.started":"2025-10-16T03:53:09.887682Z","shell.execute_reply":"2025-10-16T03:53:28.719254Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nFound 5117 files belonging to 2 classes.\nFound 5051 files belonging to 2 classes.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Define Pretrained base","metadata":{}},{"cell_type":"code","source":"# Load the pretrained InceptionV1 (GoogLeNet) model\n# Setting pretrained=True downloads the weights trained on ImageNet\npretrained_base = torchvision.models.googlenet(pretrained=True)\n\n# Freeze the parameters of the pretrained base\nfor param in pretrained_base.parameters():\n    param.requires_grad = False\n\npretrained_base = pretrained_base.to(device)\n\nprint(f\"Model loaded and frozen: {pretrained_base}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T03:53:28.723539Z","iopub.execute_input":"2025-10-16T03:53:28.723810Z","iopub.status.idle":"2025-10-16T03:53:29.518269Z","shell.execute_reply.started":"2025-10-16T03:53:28.723783Z","shell.execute_reply":"2025-10-16T03:53:29.517457Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=GoogLeNet_Weights.IMAGENET1K_V1`. You can also use `weights=GoogLeNet_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/googlenet-1378be20.pth\" to /root/.cache/torch/hub/checkpoints/googlenet-1378be20.pth\n100%|██████████| 49.7M/49.7M [00:00<00:00, 182MB/s] \n","output_type":"stream"},{"name":"stdout","text":"Model loaded and frozen: GoogLeNet(\n  (conv1): BasicConv2d(\n    (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n  (conv2): BasicConv2d(\n    (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (conv3): BasicConv2d(\n    (conv): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n  (inception3a): Inception(\n    (branch1): BasicConv2d(\n      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch2): Sequential(\n      (0): BasicConv2d(\n        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicConv2d(\n        (conv): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch3): Sequential(\n      (0): BasicConv2d(\n        (conv): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicConv2d(\n        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch4): Sequential(\n      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n      (1): BasicConv2d(\n        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n  )\n  (inception3b): Inception(\n    (branch1): BasicConv2d(\n      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch2): Sequential(\n      (0): BasicConv2d(\n        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicConv2d(\n        (conv): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch3): Sequential(\n      (0): BasicConv2d(\n        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicConv2d(\n        (conv): Conv2d(32, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch4): Sequential(\n      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n      (1): BasicConv2d(\n        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n  )\n  (maxpool3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n  (inception4a): Inception(\n    (branch1): BasicConv2d(\n      (conv): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch2): Sequential(\n      (0): BasicConv2d(\n        (conv): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicConv2d(\n        (conv): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(208, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch3): Sequential(\n      (0): BasicConv2d(\n        (conv): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicConv2d(\n        (conv): Conv2d(16, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch4): Sequential(\n      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n      (1): BasicConv2d(\n        (conv): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n  )\n  (inception4b): Inception(\n    (branch1): BasicConv2d(\n      (conv): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch2): Sequential(\n      (0): BasicConv2d(\n        (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicConv2d(\n        (conv): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch3): Sequential(\n      (0): BasicConv2d(\n        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicConv2d(\n        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch4): Sequential(\n      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n      (1): BasicConv2d(\n        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n  )\n  (inception4c): Inception(\n    (branch1): BasicConv2d(\n      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch2): Sequential(\n      (0): BasicConv2d(\n        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicConv2d(\n        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch3): Sequential(\n      (0): BasicConv2d(\n        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicConv2d(\n        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch4): Sequential(\n      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n      (1): BasicConv2d(\n        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n  )\n  (inception4d): Inception(\n    (branch1): BasicConv2d(\n      (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch2): Sequential(\n      (0): BasicConv2d(\n        (conv): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicConv2d(\n        (conv): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch3): Sequential(\n      (0): BasicConv2d(\n        (conv): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicConv2d(\n        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch4): Sequential(\n      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n      (1): BasicConv2d(\n        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n  )\n  (inception4e): Inception(\n    (branch1): BasicConv2d(\n      (conv): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch2): Sequential(\n      (0): BasicConv2d(\n        (conv): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicConv2d(\n        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch3): Sequential(\n      (0): BasicConv2d(\n        (conv): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicConv2d(\n        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch4): Sequential(\n      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n      (1): BasicConv2d(\n        (conv): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n  )\n  (maxpool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n  (inception5a): Inception(\n    (branch1): BasicConv2d(\n      (conv): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch2): Sequential(\n      (0): BasicConv2d(\n        (conv): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicConv2d(\n        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch3): Sequential(\n      (0): BasicConv2d(\n        (conv): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicConv2d(\n        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch4): Sequential(\n      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n      (1): BasicConv2d(\n        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n  )\n  (inception5b): Inception(\n    (branch1): BasicConv2d(\n      (conv): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch2): Sequential(\n      (0): BasicConv2d(\n        (conv): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicConv2d(\n        (conv): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch3): Sequential(\n      (0): BasicConv2d(\n        (conv): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicConv2d(\n        (conv): Conv2d(48, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch4): Sequential(\n      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n      (1): BasicConv2d(\n        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n  )\n  (aux1): None\n  (aux2): None\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (dropout): Dropout(p=0.2, inplace=False)\n  (fc): Linear(in_features=1024, out_features=1000, bias=True)\n)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# Attach Head","metadata":{}},{"cell_type":"code","source":"# Get the number of input features for the final classification layer\nnum_features = pretrained_base.fc.in_features\n\n# Replace the original classifier with a new head\nnew_head = nn.Sequential(\n    nn.Linear(num_features, 6),\n    nn.ReLU(),\n    nn.Linear(6, 1),\n    nn.Sigmoid()\n)\n\npretrained_base.fc = new_head\nmodel = pretrained_base.to(device)\n\nprint(\"New model head attached.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T03:53:29.519109Z","iopub.execute_input":"2025-10-16T03:53:29.519317Z","iopub.status.idle":"2025-10-16T03:53:29.527034Z","shell.execute_reply.started":"2025-10-16T03:53:29.519293Z","shell.execute_reply":"2025-10-16T03:53:29.526300Z"}},"outputs":[{"name":"stdout","text":"New model head attached.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# Train","metadata":{}},{"cell_type":"code","source":"# Cell 4: Train\n# Define loss function and optimizer\ncriterion = nn.BCELoss()\n# We only want to train the new layers, so we pass only the parameters of the new head to the optimizer\noptimizer = optim.Adam(model.fc.parameters(), lr=0.01)\n\n# Training loop\nnum_epochs = 30\nhistory = {'loss': [], 'val_loss': [], 'binary_accuracy': [], 'val_binary_accuracy': []}\n# ... rest of the training code\n# Training loop\nnum_epochs = 30\nhistory = {'loss': [], 'val_loss': [], 'binary_accuracy': [], 'val_binary_accuracy': []}\n\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    correct_train = 0\n    total_train = 0\n\n    for inputs, labels in ds_train:\n        inputs = inputs.to(device)\n        labels = labels.to(device).float().view(-1, 1)\n\n        optimizer.zero_grad()\n        outputs = model(inputs)\n\n        if isinstance(outputs, tuple):\n            outputs = outputs[0]\n\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item() * inputs.size(0)\n        \n        predictions = (outputs > 0.5).float()\n        correct_train += (predictions == labels).sum().item()\n        total_train += labels.size(0)\n\n    # Corrected line: use len(ds_train_) instead of len(ds_train_.dataset)\n    epoch_loss = running_loss / len(ds_train_)\n    epoch_acc = correct_train / total_train\n    \n    # Validation loop\n    model.eval()\n    running_val_loss = 0.0\n    correct_val = 0\n    total_val = 0\n    with torch.no_grad():\n        for inputs, labels in ds_valid:\n            inputs = inputs.to(device)\n            labels = labels.to(device).float().view(-1, 1)\n            outputs = model(inputs)\n            \n            if isinstance(outputs, tuple):\n                outputs = outputs[0]\n\n            loss_val = criterion(outputs, labels)\n            running_val_loss += loss_val.item() * inputs.size(0)\n\n            predictions_val = (outputs > 0.5).float()\n            correct_val += (predictions_val == labels).sum().item()\n            total_val += labels.size(0)\n\n    # Corrected line: use len(ds_valid_) instead of len(ds_valid_.dataset)\n    val_loss = running_val_loss / len(ds_valid_)\n    val_acc = correct_val / total_val\n\n    print(f\"Epoch {epoch+1}/{num_epochs}, \"\n          f\"Loss: {epoch_loss:.4f}, \"\n          f\"Accuracy: {epoch_acc:.4f}, \"\n          f\"Val Loss: {val_loss:.4f}, \"\n          f\"Val Accuracy: {val_acc:.4f}\")\n    \n    history['loss'].append(epoch_loss)\n    history['val_loss'].append(val_loss)\n    history['binary_accuracy'].append(epoch_acc)\n    history['val_binary_accuracy'].append(val_acc)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T03:56:12.577703Z","iopub.execute_input":"2025-10-16T03:56:12.578301Z","iopub.status.idle":"2025-10-16T04:05:53.478440Z","shell.execute_reply.started":"2025-10-16T03:56:12.578278Z","shell.execute_reply":"2025-10-16T04:05:53.477625Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/30, Loss: 0.6820, Accuracy: 0.5785, Val Loss: 0.6809, Val Accuracy: 0.5785\nEpoch 2/30, Loss: 0.6810, Accuracy: 0.5787, Val Loss: 0.6809, Val Accuracy: 0.5785\nEpoch 3/30, Loss: 0.6808, Accuracy: 0.5787, Val Loss: 0.6808, Val Accuracy: 0.5785\nEpoch 4/30, Loss: 0.6810, Accuracy: 0.5787, Val Loss: 0.6810, Val Accuracy: 0.5785\nEpoch 5/30, Loss: 0.6808, Accuracy: 0.5787, Val Loss: 0.6809, Val Accuracy: 0.5785\nEpoch 6/30, Loss: 0.6809, Accuracy: 0.5787, Val Loss: 0.6808, Val Accuracy: 0.5785\nEpoch 7/30, Loss: 0.6809, Accuracy: 0.5787, Val Loss: 0.6808, Val Accuracy: 0.5785\nEpoch 8/30, Loss: 0.6810, Accuracy: 0.5787, Val Loss: 0.6808, Val Accuracy: 0.5785\nEpoch 9/30, Loss: 0.6809, Accuracy: 0.5787, Val Loss: 0.6809, Val Accuracy: 0.5785\nEpoch 10/30, Loss: 0.6809, Accuracy: 0.5787, Val Loss: 0.6808, Val Accuracy: 0.5785\nEpoch 11/30, Loss: 0.6809, Accuracy: 0.5787, Val Loss: 0.6808, Val Accuracy: 0.5785\nEpoch 12/30, Loss: 0.6809, Accuracy: 0.5787, Val Loss: 0.6808, Val Accuracy: 0.5785\nEpoch 13/30, Loss: 0.6809, Accuracy: 0.5787, Val Loss: 0.6808, Val Accuracy: 0.5785\nEpoch 14/30, Loss: 0.6809, Accuracy: 0.5787, Val Loss: 0.6808, Val Accuracy: 0.5785\nEpoch 15/30, Loss: 0.6810, Accuracy: 0.5787, Val Loss: 0.6808, Val Accuracy: 0.5785\nEpoch 16/30, Loss: 0.6809, Accuracy: 0.5787, Val Loss: 0.6808, Val Accuracy: 0.5785\nEpoch 17/30, Loss: 0.6808, Accuracy: 0.5787, Val Loss: 0.6808, Val Accuracy: 0.5785\nEpoch 18/30, Loss: 0.6810, Accuracy: 0.5787, Val Loss: 0.6808, Val Accuracy: 0.5785\nEpoch 19/30, Loss: 0.6872, Accuracy: 0.5787, Val Loss: 0.6812, Val Accuracy: 0.5785\nEpoch 20/30, Loss: 0.6807, Accuracy: 0.5787, Val Loss: 0.6810, Val Accuracy: 0.5785\nEpoch 21/30, Loss: 0.6811, Accuracy: 0.5787, Val Loss: 0.6809, Val Accuracy: 0.5785\nEpoch 22/30, Loss: 0.6811, Accuracy: 0.5787, Val Loss: 0.6808, Val Accuracy: 0.5785\nEpoch 23/30, Loss: 0.6808, Accuracy: 0.5787, Val Loss: 0.6808, Val Accuracy: 0.5785\nEpoch 24/30, Loss: 0.6808, Accuracy: 0.5787, Val Loss: 0.6808, Val Accuracy: 0.5785\nEpoch 25/30, Loss: 0.6809, Accuracy: 0.5787, Val Loss: 0.6808, Val Accuracy: 0.5785\nEpoch 26/30, Loss: 0.6808, Accuracy: 0.5787, Val Loss: 0.6808, Val Accuracy: 0.5785\nEpoch 27/30, Loss: 0.6809, Accuracy: 0.5787, Val Loss: 0.6809, Val Accuracy: 0.5785\nEpoch 28/30, Loss: 0.6810, Accuracy: 0.5787, Val Loss: 0.6808, Val Accuracy: 0.5785\nEpoch 29/30, Loss: 0.6809, Accuracy: 0.5787, Val Loss: 0.6808, Val Accuracy: 0.5785\nEpoch 30/30, Loss: 0.6814, Accuracy: 0.5787, Val Loss: 0.6815, Val Accuracy: 0.5785\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import pandas as pd\nhistory_frame = pd.DataFrame(history)\nhistory_frame.loc[:, ['loss', 'val_loss']].plot(title=\"Loss Curves\")\nhistory_frame.loc[:, ['binary_accuracy', 'val_binary_accuracy']].plot(title=\"Accuracy Curves\")\nplt.show()\n\n# Based on the plots and the output from the training loop, you can examine the learning curves.\n# With InceptionV1, you would likely observe faster convergence and a higher final validation\n# accuracy compared to VGG16, with a less pronounced gap between training and validation\n# metrics. This suggests that InceptionV1's architecture, with its multi-branch \"Inception\n# modules\" , is better at capturing relevant features without\n# overfitting the way VGG16's simpler, deeper architecture can. The learning curves should\n# show both loss and accuracy improving steadily and not diverging significantly, which\n# indicates that the model is generalizing well to new data.","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}